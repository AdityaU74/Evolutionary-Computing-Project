import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, models, transforms
from torch.utils.data import DataLoader

# Check if CUDA is available and set device to GPU or CPU
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f'Using device: {device}')

# Define transformations for the images
transformations = transforms.Compose([
    transforms.Resize((224, 224)),  # MobileNet v2 requires a 224x224 input
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# Load the dataset
print('Loading datasets...')
train_data = datasets.ImageFolder('dataset/chest_xray/train', transform=transformations)
test_data = datasets.ImageFolder('dataset/chest_xray/test', transform=transformations)

# Dataloaders
print('Creating dataloaders...')
train_loader = DataLoader(train_data, batch_size=32, shuffle=True)
test_loader = DataLoader(test_data, batch_size=96, shuffle=False)

def trainMobileNet(learningRate=0.01,num_epochs=5,batch_len=1):
    # Initialize MobileNet v2
    print('Initializing MobileNet v2...')
    model = models.mobilenet_v2(weights=None)
    model.classifier[1] = nn.Linear(model.last_channel, 2)  # Adjusting for binary classification

    model.to(device)

    # Loss and optimizer
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), learningRate)

    # Function to train the model
    def train_model(model, criterion, optimizer, num_epochs):
        print('Starting training...')
        model.train()  # Set model to training mode
        for epoch in range(num_epochs):
            running_loss = 0.0
            for i, (inputs, labels) in enumerate(train_loader, 1):
                inputs, labels = inputs.to(device), labels.to(device)
                optimizer.zero_grad()
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
                running_loss += loss.item() * inputs.size(0)
                
                if i >= batch_len:  # Stop after 4 batches
                    break
                
            epoch_loss = running_loss / (batch_len * train_loader.batch_size)
            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')

    # Train the model
    train_model(model, criterion, optimizer, num_epochs)

    # Save the model
    torch.save(model, 'mobilenet_v2_pneumonia_model.pt')
    print('Model saved')

def testMobileNet():
    # Load the trained SqueezeNet model
    model = torch.load("mobilenet_v2_pneumonia_model.pt")
    model = model.to(device)  # Ensure the model is on the correct device
    model.eval()  # Set the model to evaluation mode

    # Function to test the model
    def test_model(model, test_loader):
        correct = 0
        total = 0
        print("Starting model testing...")
        with torch.no_grad():  # For inference, we disable gradient calculation
            for batch_index, (images, labels) in enumerate(test_loader):
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
                print(f"Processed batch {batch_index + 1}/{len(test_loader)}")

        accuracy = 100 * correct / total
        return accuracy
        # print(f'Accuracy of the model on the test images: {accuracy:.2f}%')

    # Test the model
    accuracy = test_model(model, test_loader)
    return accuracy

# trainMobileNet(learningRate=0.01,num_epochs=5,batch_len=1)
# testMobileNet()