{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":30097,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nimport seaborn as sns\nimport random\nimport cv2\nimport copy\nimport os\nfrom sklearn.model_selection import train_test_split\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.models as models\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.utils import make_grid\nimport torchvision.transforms as transform\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nfrom PIL import Image\n\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\n \ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/chest-xray-pneumonia/chest_xray/chest_xray'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_samplesize = pd.DataFrame.from_dict(\n    {'Normal': [len([os.path.join(path+'/train/NORMAL', filename) \n                     for filename in os.listdir(path+'/train/NORMAL')])], \n     'Pneumonia': [len([os.path.join(path+'/train/PNEUMONIA', filename) \n                        for filename in os.listdir(path+'/train/PNEUMONIA')])]})\n\n\nsns.barplot(data=train_samplesize).set_title('Training Set Data Inbalance', fontsize=20)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformer = {\n    'dataset1': transform.Compose([transform.Resize(255),\n                                            transform.CenterCrop(224),\n                                            transform.RandomHorizontalFlip(),\n                                            transform.RandomRotation(10),\n                                            transform.RandomGrayscale(),\n                                            transform.RandomAffine(translate=(0.05,0.05), degrees=0),\n                                            transform.ToTensor()\n                                           ]),\n    \n    'dataset2' : transform.Compose([transform.Resize(255),\n                                            transform.CenterCrop(224),\n                                            transform.RandomHorizontalFlip(p=1),\n                                            transform.RandomGrayscale(),\n                                            transform.RandomAffine(translate=(0.1,0.05), degrees=10),\n                                            transform.ToTensor()\n                                    \n                                           ]),\n    'dataset3' : transform.Compose([transform.Resize(255),\n                                            transform.CenterCrop(224),\n                                            transform.RandomHorizontalFlip(p=0.5),\n                                            transform.RandomRotation(15),\n                                            transform.RandomGrayscale(p=1),\n                                            transform.RandomAffine(translate=(0.08,0.1), degrees=15),\n                                            transform.ToTensor()\n                                           ]),\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset1 = ImageFolder(path+'/train', \n                      transform=transformer['dataset1'])\n\ndataset2 = ImageFolder(path+'/train', \n                      transform=transformer['dataset2'])\n\ndataset3 = ImageFolder(path+'/train', \n                      transform=transformer['dataset3'])\n\nnorm1, _ = train_test_split(dataset2, test_size= 3875/(1341+3875), shuffle=False)\nnorm2, _ = train_test_split(dataset3, test_size= 4023/(1341+3875), shuffle=False)\n\ndataset = ConcatDataset([dataset1, norm1, norm2])\n\nlen(dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dataset1.classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for plotting samples\ndef plot_samples(samples):  \n    fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(30,8))\n    for i in range(len(samples)):\n        image = cv2.cvtColor(imread(samples[i]), cv2.COLOR_BGR2RGB)\n        ax[i//5][i%5].imshow(image)\n        if i<5:\n            ax[i//5][i%5].set_title(\"Normal\", fontsize=20)\n        else:\n            ax[i//5][i%5].set_title(\"Pneumonia\", fontsize=20)\n        ax[i//5][i%5].axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rand_samples = random.sample([os.path.join(path+'/train/NORMAL', filename) \n                              for filename in os.listdir(path+'/train/NORMAL')], 5) + \\\n    random.sample([os.path.join(path+'/train/PNEUMONIA', filename) \n                   for filename in os.listdir(path+'/train/PNEUMONIA')], 5)\n\nplot_samples(rand_samples)\nplt.suptitle('Training Set Samples', fontsize=30)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set random seed so we get the same sampling every time for reproducibility\n\nrandom_seed = 2020\ntorch.manual_seed(random_seed);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds, val_ds = train_test_split(dataset, test_size=0.3, random_state=random_seed)\nlen(train_ds), len(val_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size=50\n\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\nval_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\nloaders = {'train':train_dl, 'val':val_dl}\ndataset_sizes = {'train':len(train_ds), 'val':len(val_ds)}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(12, 12))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images[:60], nrow=10).permute(1, 2, 0))\n        break\n        \nshow_batch(train_dl)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1) \n    return torch.tensor(torch.sum(preds == labels).item() / len(preds)), preds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torchvision.models.densenet161(pretrained=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False\n    \nin_features = model.classifier.in_features\n\nmodel.classifier = nn.Linear(in_features, 2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save the losses for further visualization\nlosses = {'train':[], 'val':[]}\naccuracies = {'train':[], 'val':[]}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, criterion, optimizer, scheduler, epochs):\n  since = time.time()\n  best_model = copy.deepcopy(model.state_dict())\n  best_acc = 0.0\n  for epoch in range(epochs):\n    for phase in ['train', 'val']:\n      if phase == 'train':\n        model.train()\n      else:\n        model.eval()\n      \n      running_loss = 0.0\n      running_corrects = 0.0\n\n      for inputs, labels in loaders[phase]:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        with torch.set_grad_enabled(phase=='train'):\n          outp = model(inputs)\n          _, pred = torch.max(outp, 1)\n          loss = criterion(outp, labels)\n        \n          if phase == 'train':\n            loss.backward()\n            optimizer.step()\n        \n        running_loss += loss.item()*inputs.size(0)\n        running_corrects += torch.sum(pred == labels.data)\n\n\n      epoch_loss = running_loss / dataset_sizes[phase]\n      epoch_acc = running_corrects.double()/dataset_sizes[phase]\n      losses[phase].append(epoch_loss)\n      accuracies[phase].append(epoch_acc)\n      if phase == 'train':\n        print('Epoch: {}/{}'.format(epoch+1, epochs))\n      print('{} - loss:{}, accuracy{}'.format(phase, epoch_loss, epoch_acc))\n    \n      if phase == 'val':\n        print('Time: {}m {}s'.format((time.time()- since)//60, (time.time()- since)%60))\n            \n      if phase == 'val' and epoch_acc > best_acc:\n        best_acc = epoch_acc\n        best_model = copy.deepcopy(model.state_dict())\n    scheduler.step()  \n  time_elapsed = time.time() - since\n  print('Training Time {}m {}s'.format(time_elapsed//60, time_elapsed%60)) \n  print('Best accuracy {}'.format(best_acc))\n\n  model.load_state_dict(best_model)\n  return model   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.classifier.parameters(), lr = 0.001)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, 4, gamma=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(device)\nepochs = 10\nmodel = train(model, criterion, optimizer, scheduler, epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = True\n    \noptimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n\nmodel.to(device)\ngrad_clip = None\nweight_decay = 1e-4\n# weighted loss for data class imbalance\nepochs = 10\nmodel = train(model, criterion, optimizer, scheduler, epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\nt = f.suptitle('Performance', fontsize=12)\nf.subplots_adjust(top=0.85, wspace=0.3)\n\nepoch_list = list(range(1,epochs*2+1))\nax1.plot(epoch_list, accuracies['train'], label='Train Accuracy')\nax1.plot(epoch_list, accuracies['val'], label='Validation Accuracy')\nax1.set_xticks(np.arange(0, epochs*2+1, 5))\nax1.set_ylabel('Accuracy Value')\nax1.set_xlabel('Epoch')\nax1.set_title('Accuracy')\nl1 = ax1.legend(loc=\"best\")\n\nax2.plot(epoch_list, losses['train'], label='Train Loss')\nax2.plot(epoch_list, losses['val'], label='Validation Loss')\nax2.set_xticks(np.arange(0, epochs*2+1, 5))\nax2.set_ylabel('Loss Value')\nax2.set_xlabel('Epoch')\nax2.set_title('Loss')\nl2 = ax2.legend(loc=\"best\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_samplesize = pd.DataFrame.from_dict(\n    {'Normal': [len([os.path.join(path+'/test/NORMAL', filename) \n                     for filename in os.listdir(path+'/test/NORMAL')])], \n     'Pneumonia': [len([os.path.join(path+'/test/PNEUMONIA', filename) \n                        for filename in os.listdir(path+'/test/PNEUMONIA')])]})\n\nsns.barplot(data=test_samplesize).set_title('Test Set Data Inbalance', fontsize=20)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validation_step(batch):\n        images,labels = batch\n        images,labels = images.to(device),labels.to(device)\n        out = model(images)                                      \n        loss = F.cross_entropy(out, labels)                    \n        acc,preds = accuracy(out, labels)                       \n        \n        return {'val_loss': loss.detach(), 'val_acc':acc.detach(), \n                'preds':preds.detach(), 'labels':labels.detach()}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" def test_prediction(outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()           \n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()             \n        # combine predictions\n        batch_preds = [pred for x in outputs for pred in x['preds'].tolist()] \n        # combine labels\n        batch_labels = [lab for x in outputs for lab in x['labels'].tolist()]  \n        \n        return {'test_loss': epoch_loss.item(), 'test_acc': epoch_acc.item(),\n                'test_preds': batch_preds, 'test_labels': batch_labels}  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef test_predict(model, test_loader):\n    model.eval()\n    # perform testing for each batch\n    outputs = [validation_step(batch) for batch in test_loader] \n    results = test_prediction(outputs)                          \n    print('test_loss: {:.4f}, test_acc: {:.4f}'\n          .format(results['test_loss'], results['test_acc']))\n    \n    return results['test_preds'], results['test_labels']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testset = ImageFolder(path+'/test', \n                           transform=transform.Compose([transform.Resize(255),\n                                                 transform.CenterCrop(224),                                                              \n                                                 transform.ToTensor(),\n                                                ]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dl = DataLoader(testset, batch_size=256)\nmodel.to(device)\npreds,labels = test_predict(model, test_dl)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot confusion matrix\ncm  = confusion_matrix(labels, preds)\nplt.figure()\nplot_confusion_matrix(cm,figsize=(12,8),cmap=plt.cm.Blues)\nplt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\nplt.xlabel('Predicted Label',fontsize=18)\nplt.ylabel('True Label',fontsize=18)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compute Performance Metrics\ntn, fp, fn, tp = cm.ravel()\n\naccuracy = (np.array(preds) == np.array(labels)).sum() / len(preds)\nprecision = tp/(tp+fp)\nrecall = tp/(tp+fn)\nf1 = 2*((precision*recall)/(precision+recall))\n\nprint(\"Accuracy of the model is {:.2f}\".format(accuracy))\nprint(\"Recall of the model is {:.2f}\".format(recall))\nprint(\"Precision of the model is {:.2f}\".format(precision))\nprint(\"F1 Score of the model is {:.2f}\".format(f1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select 5 normal and 5 pneumonia images indices\nidxs = torch.tensor(np.append(np.arange(start=0, stop=5, step=1), \n                             np.arange(start=500, stop=505, step=1))) \n\nfig, ax = plt.subplots(nrows=2, ncols=5, figsize=(30,14))\n\nfor c,i in enumerate(idxs):\n    img_tensor, label = testset[i]\n    ax[c//5][c%5].imshow(img_tensor[0,:,:], cmap='gray')\n    ax[c//5][c%5].set_title('Label: {}\\nPrediction: {}'\n                            .format(testset.classes[label], \n                                    testset.classes[preds[i]]),\n                            fontsize=25)\n    ax[c//5][c%5].axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(8,12), ncols=2, nrows=4)\n\nfor row in range(4):\n    img,label = testset[row]\n    pred = torch.exp(model(img.to(device).unsqueeze(0)))\n    class_name = ['NORMAL', 'PNEUMONIA']\n    classes = np.array(class_name)\n    pred = pred.cpu().data.numpy().squeeze()\n    ax[row][0].imshow(img.permute(1, 2, 0))\n    ax[row][0].set_title('Real : {}'.format(class_name[label]))\n    ax[row][0].axis('off')\n    ax[row][1].barh(classes, pred)\n    ax[row][1].set_aspect(0.1)\n    ax[row][1].set_yticks(classes)\n    ax[row][1].set_yticklabels(classes)\n    ax[row][1].set_title('Predicted Class')\n    ax[row][1].set_xlim(0, 1.)\n    plt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}